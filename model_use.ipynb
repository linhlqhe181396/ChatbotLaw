{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMRy3UP28QfqeO0hKBxQXxD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGxeFH6BCE0N","executionInfo":{"status":"ok","timestamp":1742807511661,"user_tz":-420,"elapsed":26223,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}},"outputId":"5f1f7f9d-4691-4866-8b97-ed45bf21250b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","import joblib\n","import json\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Attention, Concatenate\n","from tensorflow.keras.models import Model"],"metadata":{"id":"qm55PiBkChOM","executionInfo":{"status":"ok","timestamp":1742807530813,"user_tz":-420,"elapsed":4188,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# L·ªõp Seq2Seq v·ªõi Attention\n","class Seq2SeqAttention(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, **kwargs):\n","        super(Seq2SeqAttention, self).__init__(**kwargs)\n","\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.encoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n","        self.decoder_lstm = tf.keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)\n","        self.attention = tf.keras.layers.Attention()\n","        self.dense = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n","\n","        # L∆∞u tham s·ªë\n","        self.vocab_size = vocab_size\n","        self.embedding_dim = embedding_dim\n","        self.hidden_size = hidden_size\n","\n","    def call(self, inputs):\n","        encoder_inputs, decoder_inputs = inputs\n","\n","        encoder_embedded = self.embedding(encoder_inputs)\n","        encoder_outputs, state_h, state_c = self.encoder_lstm(encoder_embedded)\n","\n","        decoder_embedded = self.embedding(decoder_inputs)\n","        decoder_outputs, _, _ = self.decoder_lstm(decoder_embedded, initial_state=[state_h, state_c])\n","\n","        # √Åp d·ª•ng Attention\n","        context_vector = self.attention([decoder_outputs, encoder_outputs, encoder_outputs])\n","        concat_outputs = tf.concat([decoder_outputs, context_vector], axis=-1)\n","\n","        outputs = self.dense(concat_outputs)\n","        return outputs\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"vocab_size\": self.vocab_size,\n","            \"embedding_dim\": self.embedding_dim,\n","            \"hidden_size\": self.hidden_size\n","        })\n","        return config\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        return cls(**config)\n","\n"],"metadata":{"id":"PpaDRrUXCzok","executionInfo":{"status":"ok","timestamp":1742807533387,"user_tz":-420,"elapsed":24,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WnvPnUWfB5jW","executionInfo":{"status":"ok","timestamp":1742807563270,"user_tz":-420,"elapsed":26724,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}},"outputId":"b0e6a50f-dd9a-4723-f6b6-e58b48f95122"},"outputs":[{"output_type":"stream","name":"stdout","text":[" M√¥ h√¨nh & tokenizer ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!\n"]}],"source":["save_dir = \"/content/drive/MyDrive/model_build/saved_model\"\n","\n","# Load tokenizer\n","tokenizer_path = os.path.join(save_dir, \"tokenizer.pkl\")\n","tokenizer = joblib.load(tokenizer_path)\n","\n","# Load m√¥ h√¨nh\n","model = tf.keras.models.load_model(\n","    os.path.join(save_dir, \"seq2seq_model.keras\"),\n","    custom_objects={\"Seq2SeqAttention\": Seq2SeqAttention}\n",")\n","\n","print(\" M√¥ h√¨nh & tokenizer ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!\")"]},{"cell_type":"code","source":["def generate_response(prompt, tokenizer, model, max_length=150):\n","    # Token h√≥a prompt ƒë·∫ßu v√†o\n","    encoded_prompt = tokenizer(prompt, return_tensors=\"tf\", padding=True, truncation=True, max_length=max_length)\n","    input_ids = encoded_prompt[\"input_ids\"]\n","    attention_mask = encoded_prompt[\"attention_mask\"]\n","\n","    # Ki·ªÉm tra tokenizer c√≥ bos/eos token kh√¥ng\n","    if tokenizer.bos_token_id is not None:\n","        start_token = tokenizer.bos_token_id\n","    else:\n","        start_token = tokenizer.cls_token_id  # D√πng [CLS] n·∫øu kh√¥ng c√≥ bos_token_id\n","\n","    if tokenizer.eos_token_id is not None:\n","        end_token = tokenizer.eos_token_id\n","    else:\n","        end_token = tokenizer.sep_token_id  # D√πng [SEP] n·∫øu kh√¥ng c√≥ eos_token_id\n","\n","    # Kh·ªüi t·∫°o decoder v·ªõi token b·∫Øt ƒë·∫ßu\n","    decoder_input = tf.convert_to_tensor([[start_token]], dtype=tf.int32)\n","    response_ids = []\n","\n","    for _ in range(max_length):\n","        # D·ª± ƒëo√°n t·ª´ ti·∫øp theo\n","        predictions = model([input_ids, decoder_input], training=False)\n","        predicted_id = tf.argmax(predictions[:, -1, :], axis=-1).numpy()[0]\n","\n","        if predicted_id == end_token:\n","            break\n","\n","        response_ids.append(predicted_id)\n","        decoder_input = tf.concat([decoder_input, tf.convert_to_tensor([[predicted_id]], dtype=tf.int32)], axis=1)\n","\n","    # Gi·∫£i m√£ output\n","    response_text = tokenizer.decode(response_ids, skip_special_tokens=True)\n","    return response_text\n"],"metadata":{"id":"MImkhgcqCHjM","executionInfo":{"status":"ok","timestamp":1742807569431,"user_tz":-420,"elapsed":15,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["prompt = \"c√≥ ƒë∆∞·ª£c b√°n ƒë·∫•t n√¥ng nghi·ªáp kh√¥ng?\""],"metadata":{"id":"IfKSbcwDCIPk","executionInfo":{"status":"ok","timestamp":1742807578917,"user_tz":-420,"elapsed":56,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","response = generate_response(prompt, tokenizer, model)\n","\n","print(\"üöÄ Bot tr·∫£ l·ªùi:\", response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTrAb0jUCMYM","executionInfo":{"status":"ok","timestamp":1742807591614,"user_tz":-420,"elapsed":2127,"user":{"displayName":"Le Quang Linh (K18 HL)","userId":"00375792345137964817"}},"outputId":"194c18d1-ef16-405b-fbbe-6e45a3d99061"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Bot tr·∫£ l·ªùi: Kh√¥ng, tr·ª´ tr∆∞·ªùng h·ª£p nh·∫•t m·ª•c ƒë√≠ch s·ª≠ d·ª•ng ƒë·∫•t.\n"]}]}]}